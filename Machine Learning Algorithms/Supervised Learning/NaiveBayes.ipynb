{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cadae93-96e1-49ac-a2b5-ee37389e9a5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe278b31-e3ce-4882-a76c-0ee967f2511d",
   "metadata": {},
   "source": [
    "# Naive Bayes\n",
    "\n",
    "Naive Bayes is a classification algorithm that predicts the probability of an input's class based on its features. It's based on Bayes' theorem, which calculates the probability of a hypothesis being true given the evidence. It's known for simplicity, speed, and effectiveness, particularly in text classification tasks. \n",
    "\n",
    "[Naive Bayes, Clearly Explained!!!](https://youtu.be/O2L2Uv9pdDA?si=r1I-t3QSuMnGW18W)  \n",
    "[Gaussian Naive Bayes, Clearly Explained!!!](https://youtu.be/H3EjCKtlVog?si=3n4x1aZ6gHI1JJPW)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363297c1-98f6-480a-88bc-3220c9960d1e",
   "metadata": {},
   "source": [
    "![](https://databasecamp.de/wp-content/uploads/naive-bayes-overview-1024x709.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb36d852-3a68-49f8-bfc1-f779a94eb76d",
   "metadata": {},
   "source": [
    "## Intuition\n",
    "\n",
    "Naive Bayes, relies on the principle of conditional probability. It assumes that features are independent given the class label. This simplifies calculations, making it computationally efficient, especially for large datasets. In categorical data, it predicts class probabilities, while in numerical data, it estimates conditional probabilities of the target variable. Despite its simplifying *naive* assumption, Naive Bayes often performs remarkably well, particularly with text data. Its speed and simplicity make it suitable for real-time applications. While not without limitations, it serves as a solid baseline for various tasks in  classifications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad89df3-76ca-49be-abc0-89d7b1bc5ff0",
   "metadata": {},
   "source": [
    "**Prior Probability**:\n",
    "\n",
    "   $$P(y) = \\frac{{\\text{Number of samples with target/class } y}}{{\\text{Total number of samples}}}$$\n",
    "\n",
    "**Conditional Probability of Feature Given Target/Class**:\n",
    "\n",
    "   $$P(X_i|y) = \\frac{{\\text{Number of samples with feature } X_i \\text{ and target/class } y}}{{\\text{Number of samples with target/class } y}}$$\n",
    "\n",
    "**Posterior Probability using Bayes' Theorem**:\n",
    "\n",
    "   $$P(y|X_{\\text{test}}) = \\frac{{P(X_{\\text{test}}|y) \\cdot P(y)}}{{P(X_{\\text{test}})}}$$\n",
    "\n",
    "- where $P(X_{\\text{test}}|y)$ is calculated using the Naive Bayes assumption of feature independence: \n",
    "\n",
    "   $$P(X_{\\text{test}}|y) = \\Pi_{i=1}^n P(X_i|y) = P(X_1|y) \\times P(X_2|y) \\times \\ldots \\times P(X_n|y)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6df80a6-326f-4372-8eb7-ed2831b68128",
   "metadata": {},
   "source": [
    "## Algorithm\n",
    "\n",
    "\n",
    "1. **Input Data**: Receive labeled training data consisting of features $X$ and corresponding class labels $y$ for classification or continuous target variable $y$ for regression.\n",
    "2. **Training Phase**:\n",
    "   - Calculate prior probabilities of each class $P(y)$ or probability density function of $y$.\n",
    "   - Compute conditional probabilities of each feature given the class $P(X_i|y)$.\n",
    "3. **Prediction**:\n",
    "   - For classification: Given a new input $X_{\\text{test}}$, calculate $P(y|X_{\\text{test}})$ using Bayes' theorem. Choose the class with the highest probability as the predicted class for $X_{\\text{test}}$.\n",
    "   - For regression: Given a new input $X_{\\text{test}}$, calculate the conditional probability density function $P(y|X_{\\text{test}})$ using Bayes' theorem. Estimate the expected value of the target variable $y$ using the conditional probability density function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f63c73-9a77-4974-af61-33b30e52d57e",
   "metadata": {},
   "source": [
    "## Types of Input Features\n",
    "\n",
    "1. Categorical Features\n",
    "2. Numerical Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b56746c-1372-434f-8961-072a5c9bb372",
   "metadata": {},
   "source": [
    "### Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b5d45c1-0679-419f-b13e-b3f604345ff5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>review</th>\n",
       "      <th>education</th>\n",
       "      <th>purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>60</td>\n",
       "      <td>Female</td>\n",
       "      <td>Poor</td>\n",
       "      <td>School</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>25</td>\n",
       "      <td>Female</td>\n",
       "      <td>Good</td>\n",
       "      <td>UG</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Male</td>\n",
       "      <td>Good</td>\n",
       "      <td>School</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>38</td>\n",
       "      <td>Female</td>\n",
       "      <td>Good</td>\n",
       "      <td>PG</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>74</td>\n",
       "      <td>Male</td>\n",
       "      <td>Good</td>\n",
       "      <td>UG</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  gender review education purchased\n",
       "7    60  Female   Poor    School       Yes\n",
       "49   25  Female   Good        UG        No\n",
       "18   19    Male   Good    School        No\n",
       "47   38  Female   Good        PG       Yes\n",
       "11   74    Male   Good        UG       Yes"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link = 'https://raw.githubusercontent.com/daaanishhh002/MachineLearning/main/Datasets/education.csv'\n",
    "df = pd.read_csv(link)\n",
    "\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85bacc1d-ecbd-44f8-810f-f61f67f30b58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = df.iloc[:,:-1]\n",
    "y = df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f52acec-51f4-4a95-9234-ccb0c13fb217",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_encoded = pd.get_dummies(X,drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "562bf28a-685c-4380-b4d9-1cc484507369",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X_encoded,y,test_size=0.2,random_state=2002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8f527a2a-8696-4ad2-a2d5-f02d77c22fbd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import CategoricalNB\n",
    "cnb = CategoricalNB()\n",
    "\n",
    "cnb.fit(X_train,y_train)\n",
    "cnb.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b34ca8d2-8ca2-49eb-9b02-93cefb3e3ecf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6b4bf991-1ad3-43c2-bcca-a90d5da84b25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gnb = GaussianNB()\n",
    "bnb = BernoulliNB()\n",
    "mnb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ea0560ae-33ab-4d8a-b312-e8a64eb5aab9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb.fit(X_train,y_train)\n",
    "bnb.fit(X_train,y_train)\n",
    "mnb.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1d2d6485-9c37-4d17-a1af-4546515c06e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb.score(X_test,y_test)\n",
    "bnb.score(X_test,y_test)\n",
    "mnb.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e81135-c0a2-4fe4-9a36-d6d5b6a456bd",
   "metadata": {},
   "source": [
    "### Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ebb76c1f-140b-4210-9ad4-56a98b6505a7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9777777777777777"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn import metrics\n",
    "iris = load_iris()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.3, random_state=42)\n",
    "\n",
    "model = GaussianNB()\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edc5d86-a3d4-4ba8-8e1a-13c95009d93d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
