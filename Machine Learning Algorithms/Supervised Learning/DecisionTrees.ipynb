{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2c2c5c-206e-4eca-9b2b-12e7e09e96cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "349ef2e9-e7f2-4b71-b3ff-99978654cca4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Decision Trees\n",
    "\n",
    "They are a type of model used in machine learning for classification and regression tasks. They make decisions by splitting the data based on attributes, creating a tree structure where each branch represents a decision and each leaf represents an outcome. \n",
    "\n",
    "They're simple, interpretable, and can handle both numerical and categorical data. However, they can overfit and may need pruning or ensemble methods to improve performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e24aec-1bd8-45b8-b01e-30ca5067362f",
   "metadata": {},
   "source": [
    "![](https://www.mastersindatascience.org/wp-content/uploads/sites/54/2022/05/tree-graphic.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e476ce13-aaa5-47c2-9607-aced8794b25e",
   "metadata": {},
   "source": [
    "## Types of Decision Trees\n",
    "\n",
    "1. Classification Trees\n",
    "2. Regression Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4cf33d-426d-41c4-9d18-efd141f36abd",
   "metadata": {},
   "source": [
    "## Entropy\n",
    "\n",
    "It is a measure of impurity or disorder in a dataset. It's used to decide how to split the data at each node of the tree. The goal is to minimize entropy, which means maximizing the homogeneity of the subsets created by the split. Entropy helps the decision tree algorithm determine the best attribute to split the data on for optimal classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc46d84-2645-4135-a024-4fdf20a67610",
   "metadata": {},
   "source": [
    "$$H(X) = -\\sum_{i=1}^{n} p_i \\log_2(p_i)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3249c99b-c475-415f-9887-23a9b4b0ec32",
   "metadata": {},
   "source": [
    "![](https://miro.medium.com/v2/resize:fit:565/1*M15RZMSk8nGEyOnD8haF-A.png)\n",
    "\n",
    "We conclude that:\n",
    "- More the uncertainty, more the entropy. \n",
    "\n",
    "We can then define entropy as the measure of uncertainty."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae72b97-f739-429a-a000-c50ba44a85e9",
   "metadata": {},
   "source": [
    "## Information Gain\n",
    "\n",
    "It is a measure used in decision trees to determine the effectiveness of a particular attribute in classifying data. It quantifies how much a given attribute reduces uncertainty in the data. It helps decide which attribute to split on by comparing the entropy or impurity before and after the split, aiming to maximize the gain and thus improve the purity of the resulting subsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bfc8dc-0acc-4d46-a5e6-8380acf20a1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
