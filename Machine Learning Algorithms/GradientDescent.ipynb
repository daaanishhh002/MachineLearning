{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec5315c2-3790-4278-95d2-a97aa8cb5856",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_diabetes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8105994-9d1f-47bc-9543-fd1e81a696dc",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Gradient Descent\n",
    "\n",
    "Gradient descent is a method for unconstrained mathematical **optimization**. It is a first-order iterative algorithm for finding a **local minimum** of a differentiable multivariate function. It is particularly useful in machine learning for minimizing the cost or loss function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab86e8bb-b543-439e-a613-b9a07213b863",
   "metadata": {},
   "source": [
    "The idea is to take **repeated steps in the opposite direction of the gradient** (or approximate gradient) of the function at the current point, because this is the direction of steepest descent. Conversely, stepping in the direction of the gradient will lead to a local maximum of that function; the procedure is then known as gradient ascent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2384f8-88e4-4cc4-96ef-a0cbd61dff0a",
   "metadata": {},
   "source": [
    "![](https://easyai.tech/wp-content/uploads/2019/01/tiduxiajiang-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dddf8e75-e2da-4399-a7c7-9769058715a1",
   "metadata": {},
   "source": [
    "## Intuition\n",
    "\n",
    "Gradient descent operates on the principle of iteratively refining model parameters to minimize the cost function, drawing an analogy to navigating terrain to find the lowest point. In this analogy, the cost function represents the landscape's elevation, and the model parameters correspond to the current location. Initially, the algorithm starts at a random point on the landscape and senses the slope beneath its feet. By computing the gradient of the cost function, it determines the direction of the steepest descent. Each step taken in this direction adjusts the parameters, gradually descending towards the valley floor, where the cost function is minimized. Through repeated iterations, the algorithm refines the parameters until it reaches a point where the slope is nearly flat, signifying convergence to a local or global minimum. Ultimately, gradient descent guides the model towards optimal parameter values, effectively minimizing the cost function and improving model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bca4d7a-d9d9-4f6d-8c8d-b27bfee6cef5",
   "metadata": {},
   "source": [
    "$$\\hat{y_i} = w_1x_1 + w_2x_2 + \\dots + w_nx_n + b$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a92bc02-1025-406d-af0e-ca10fc03c4cc",
   "metadata": {},
   "source": [
    "$$\\text{Loss Function: J (w,b)} = \\sum_{i=1}^D (\\hat{y_i}-y_i)^2 = \\sum_{i=1}^D ({w_1x_1 + w_2x_2 + \\dots + w_nx_n + b}-y_i)^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe3d394-cbfe-4499-9e11-74fa0a4f0eb9",
   "metadata": {},
   "source": [
    "$$\\frac{\\partial{J}}{\\partial{w}} = 2  $$  \n",
    "$$\\frac{\\partial{J}}{\\partial{b}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5281e385-287a-40d9-bb16-6861d0d5d7d4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Algorithm of Gradient Descent\n",
    "\n",
    "1. Initialize model parameters randomly or with predefined values.\n",
    "2. Compute the gradient of the cost function with respect to the parameters using all training examples.\n",
    "3. Update parameters by subtracting the product of the learning rate and the gradient.\n",
    "4. Repeat steps 2 and 3 until convergence or a maximum number of iterations is reached."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c03591-c85f-413a-a760-e1c577266081",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Types of Gradient Descent\n",
    "\n",
    "1. Batch Gradient Descent\n",
    "2. Stochastic Gradient Descent\n",
    "3. Mini Batch Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e26c9dd-6067-4d2b-a7a0-e1bb3c52260c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Batch Gradient Descent\n",
    "\n",
    "It updates model parameters using gradients computed over the entire training dataset in each iteration. It offers stable convergence but can be computationally expensive, especially for large datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "32f791a9-e939-48d0-8b3c-bb5c7165c523",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X,y = load_diabetes(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "87e5ea0c-6301-4db6-8246-e0fcd0861484",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=2002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "bf09c713-b738-499a-865f-939be1aa5dd8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression()\n",
    "\n",
    "lr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "ff48c35f-c7ae-416d-b580-e5940d3d77a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49731505640194407"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "913cef07-cae6-4fac-8db2-434f04147f34",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  -47.92919504,  -335.02937809,   510.28947017,   350.81248009,\n",
       "        -1299.57463645,   953.75290824,   249.29502423,   173.9486256 ,\n",
       "          929.41771914,    54.59466589]),\n",
       " 148.832300854267)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.coef_, lr.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5bbd06b-89e7-44b5-9772-b634ca1aea95",
   "metadata": {},
   "source": [
    "#### Own Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "07e08811-576f-4065-90c1-4fcb86490747",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BGDRegressor:\n",
    "    \n",
    "    def __init__(self,learning_rate=0.01,epochs=100):\n",
    "        \n",
    "        self.coef_ = None\n",
    "        self.intercept_ = None\n",
    "        self.lr = learning_rate\n",
    "        self.epochs = epochs\n",
    "        \n",
    "    def fit(self,X_train,y_train):\n",
    "        # init coefs\n",
    "        self.intercept_ = 0\n",
    "        self.coef_ = np.ones(X_train.shape[1])\n",
    "        \n",
    "        for i in range(self.epochs):\n",
    "            # update all the coef and the intercept\n",
    "            y_hat = np.dot(X_train,self.coef_) + self.intercept_\n",
    "            intercept_der = -2 * np.mean(y_train - y_hat)\n",
    "            self.intercept_ = self.intercept_ - (self.lr * intercept_der)\n",
    "            \n",
    "            coef_der = -2 * np.dot((y_train - y_hat),X_train)/X_train.shape[0]\n",
    "            self.coef_ = self.coef_ - (self.lr * coef_der)\n",
    "        \n",
    "        print(self.intercept_,self.coef_)\n",
    "    \n",
    "    def predict(self,X_test):\n",
    "        return np.dot(X_test,self.coef_) + self.intercept_\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "1ef9ee38-df37-444c-8793-84311672281c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149.46680363175685 [ -29.62178873 -266.48595849  488.51570984  311.99880642  -31.21243041\n",
      "  -79.58505929 -211.99496796  124.50554176  412.00252497  110.00301171]\n"
     ]
    }
   ],
   "source": [
    "bgdr = BGDRegressor(epochs=1000,learning_rate=0.5)\n",
    "bgdr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "adf70540-d162-4884-8f26-d75a4d1b900d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5225100226742716"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "y_pred = bgdr.predict(X_test)\n",
    "r2_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bffb0d5-7d6a-4a9e-b7e4-1b10ffe0afe1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Stochastic Gradient Descent\n",
    "\n",
    "It updates model parameters using the gradient of the cost function with respect to a single training example at a time. It's efficient for large datasets, converges faster, and is robust to local minima, but can exhibit noisy convergence due to single-example updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3ae7f152-08e2-438f-a21d-e673becfad8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X,y = load_diabetes(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "185e09c4-89ca-4f61-9cf7-fd2728bfaf1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=2002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "20eb60d5-b16d-48c9-83c5-cb7b1fc09360",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression()\n",
    "\n",
    "lr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "1083d7a7-8a51-4ae8-8667-d816be7ca896",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49731505640194407"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "86af9db2-aff3-4272-8ebd-55360250aaf3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  -47.92919504,  -335.02937809,   510.28947017,   350.81248009,\n",
       "        -1299.57463645,   953.75290824,   249.29502423,   173.9486256 ,\n",
       "          929.41771914,    54.59466589]),\n",
       " 148.832300854267)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.coef_, lr.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ff7199-0c06-4997-9df3-bc3a4d22f76c",
   "metadata": {},
   "source": [
    "#### Own Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e9c8161b-2d38-44bc-9def-f7a4ec86ea88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SGDRegressor:\n",
    "    \n",
    "    def __init__(self,learning_rate=0.01,epochs=100):\n",
    "        \n",
    "        self.coef_ = None\n",
    "        self.intercept_ = None\n",
    "        self.lr = learning_rate\n",
    "        self.epochs = epochs\n",
    "        \n",
    "    def fit(self,X_train,y_train):\n",
    "        # init coefs\n",
    "        self.intercept_ = 0\n",
    "        self.coef_ = np.ones(X_train.shape[1])\n",
    "        \n",
    "        for i in range(self.epochs):\n",
    "            for j in range(X_train.shape[0]):\n",
    "                idx = np.random.randint(0,X_train.shape[0])\n",
    "                \n",
    "                y_hat = np.dot(X_train[idx],self.coef_) + self.intercept_\n",
    "                \n",
    "                intercept_der = -2 * (y_train[idx] - y_hat)\n",
    "                self.intercept_ = self.intercept_ - (self.lr * intercept_der)\n",
    "                \n",
    "                coef_der = -2 * np.dot((y_train[idx] - y_hat),X_train[idx])\n",
    "                self.coef_ = self.coef_ - (self.lr * coef_der)\n",
    "        \n",
    "        print(self.intercept_,self.coef_)\n",
    "    \n",
    "    def predict(self,X_test):\n",
    "        return np.dot(X_test,self.coef_) + self.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "831881c4-3664-4d83-bde4-37e8cacd42d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sgd = SGDRegressor(learning_rate=0.01,epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "31220958-fa41-4971-9ab2-33473ce1af4b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146.1409855015611 [  20.329438    -86.5950672   284.22881403  198.68588478   49.82538328\n",
      "   22.44773751 -143.42933769  132.06268911  250.21045523  125.15945141]\n",
      "The time taken is 0.4344296455383301\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "sgd.fit(X_train,y_train)\n",
    "print(\"The time taken is\",time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "993e8a75-78db-4913-b90f-8b058f016753",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.454568491032212"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "y_pred = sgd.predict(X_test)\n",
    "r2_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df503bb-62c9-4580-87b3-8f5c69a8eaa7",
   "metadata": {},
   "source": [
    "#### `scikit-learn` Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b51444e3-7b71-440e-98f4-4b19ebc21d61",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Danish\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SGDRegressor(learning_rate=&#x27;constant&#x27;, max_iter=100)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SGDRegressor</label><div class=\"sk-toggleable__content\"><pre>SGDRegressor(learning_rate=&#x27;constant&#x27;, max_iter=100)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SGDRegressor(learning_rate='constant', max_iter=100)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "sgd = SGDRegressor(max_iter=100,learning_rate='constant',eta0=0.01)\n",
    "sgd.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3ecb32ed-ba29-4675-923a-e99c2fcb17c9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4869186586701415"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f8785991-3705-456f-bfdb-9c6c6efde7f5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  16.70225531, -109.81478296,  320.24001347,  216.29628752,\n",
       "          38.59398519,    7.7477704 , -158.72759047,  136.87665245,\n",
       "         273.53568522,  129.82723449]),\n",
       " array([149.58456529]))"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd.coef_, sgd.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf86c9af-c65f-483a-8cfb-fb137ec9c14a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Mini Batch Gradient Descent\n",
    "\n",
    "It is a method used to train machine learning models by updating parameters based on small subsets of the training data instead of the entire dataset. It combines the efficiency of batch gradient descent with the stochastic nature of stochastic gradient descent. This approach is computationally efficient, introduces regularization, and often leads to smoother convergence during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a3de443-36ec-49b7-a2f5-59e01bd0e901",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X, y = load_diabetes(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51b0fffb-2b7c-4d17-a0be-93d738ba2669",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=2002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7a48a40-304b-45d0-ba17-7a53f7757b6c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression()\n",
    "\n",
    "lr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d38509ef-5311-4a74-878f-e7d5a213f6db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49731505640194407"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0161f1e5-4cc0-4440-bb78-6d4da92a1e0d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  -47.92919504,  -335.02937809,   510.28947017,   350.81248009,\n",
       "        -1299.57463645,   953.75290824,   249.29502423,   173.9486256 ,\n",
       "          929.41771914,    54.59466589]),\n",
       " 148.832300854267)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.coef_, lr.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946a63d5-10d1-47d8-b5c2-ba7087a2d1b7",
   "metadata": {},
   "source": [
    "#### Own Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "705d7fa1-523c-4847-89f4-a3e8d20faefc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class MBGDRegressor:\n",
    "    \n",
    "    def __init__(self,batch_size,learning_rate=0.01,epochs=100):\n",
    "        \n",
    "        self.coef_ = None\n",
    "        self.intercept_ = None\n",
    "        self.lr = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def fit(self,X_train,y_train):\n",
    "        # init coefs\n",
    "        self.intercept_ = 0\n",
    "        self.coef_ = np.ones(X_train.shape[1])\n",
    "        \n",
    "        for i in range(self.epochs):\n",
    "            \n",
    "            for j in range(int(X_train.shape[0]/self.batch_size)):\n",
    "                \n",
    "                idx = random.sample(range(X_train.shape[0]),self.batch_size)\n",
    "                \n",
    "                y_hat = np.dot(X_train[idx],self.coef_) + self.intercept_\n",
    "                intercept_der = -2 * np.mean(y_train[idx] - y_hat)\n",
    "                self.intercept_ = self.intercept_ - (self.lr * intercept_der)\n",
    "\n",
    "                coef_der = -2 * np.dot((y_train[idx] - y_hat),X_train[idx])\n",
    "                self.coef_ = self.coef_ - (self.lr * coef_der)\n",
    "        \n",
    "        print(self.intercept_,self.coef_)\n",
    "    \n",
    "    def predict(self,X_test):\n",
    "        return np.dot(X_test,self.coef_) + self.intercept_\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abb95a93-7be8-4fb4-b156-a753cbb9affc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150.28341259895402 [-1.05227941e+01 -1.99333949e+02  4.30803822e+02  2.85844475e+02\n",
      "  4.29967973e-01 -4.20797872e+01 -1.96280926e+02  1.37108720e+02\n",
      "  3.58663858e+02  1.28250832e+02]\n"
     ]
    }
   ],
   "source": [
    "mbr = MBGDRegressor(batch_size=int(X_train.shape[0]/50),learning_rate=0.01,epochs=100)\n",
    "mbr.fit(X_train,y_train)\n",
    "\n",
    "y_pred = mbr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a06c5af-4d66-4ded-9ff8-50235b2d6149",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5230814384866878"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fee33e9-b0af-4acd-8769-709ef83383b6",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### `scikit-learn` Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f74a8182-8a57-4130-86bc-9ad5fe9193da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "sgd = SGDRegressor(learning_rate='adaptive', eta0=0.15,random_state=2002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6abc2f45-1c6f-4a13-ac5f-5cb5b34b2c40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 35\n",
    "\n",
    "for i in range(100):\n",
    "    \n",
    "    idx = random.sample(range(X_train.shape[0]),batch_size)\n",
    "    sgd.partial_fit(X_train[idx],y_train[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "708ae00f-1241-44c5-acac-b10c1a479221",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5095359725795132"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0635b47a-8709-4c2d-9f10-b0493f12a50e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ -36.50045865, -179.28911745,  408.47005314,  250.31918859,\n",
       "          17.79855534,  -36.48915894, -173.66418293,  141.08146966,\n",
       "         348.14450429,  114.90907008]),\n",
       " array([149.19500524]))"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd.coef_, sgd.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0b2f0d-6bde-4eca-a92f-8ab5b8bb5080",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Batch vs Stochastic vs Mini-Batch Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ccdfa3a-e9cc-4d3c-a22a-9d729513ed7b",
   "metadata": {},
   "source": [
    "![](https://miro.medium.com/v2/resize:fit:908/1*bKSddSmLDaYszWllvQ3Z6A.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b40a1f6-59cd-4535-bbc1-28ced846385e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
